{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences. That is, for each token in “tokenized_text,” we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.\n",
    "\n",
    "If you want to process two sentences, assign each word in the first sentence plus the ‘[SEP]’ token a 0, and all tokens of the second sentence a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 segments_ids: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "cuda\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "<class 'list'> 12\n",
      "<class 'torch.Tensor'> 1\n",
      "torch.Size([1, 22, 768])\n"
     ]
    }
   ],
   "source": [
    "#text = \"Here is the sentence I want embeddings for.\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "#print('marked_text:',marked_text)\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#print (len(tokenized_text),'tokenized_text:',tokenized_text)\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#print(len(indexed_tokens),'indexed_tokens:',indexed_tokens)\n",
    "#for tup in zip(tokenized_text, indexed_tokens):\n",
    "#  print (tup)\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (len(segments_ids),'segments_ids:',segments_ids)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #hhu\n",
    "print(device)\n",
    "if device == 'cuda':\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    segments_tensors = segments_tensors.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "print(segments_tensors)\n",
    "print(type(encoded_layers),len(encoded_layers))\n",
    "print(type(encoded_layers[0]),len(encoded_layers[0]))\n",
    "print(encoded_layers[11].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 768])\n",
      "torch.Size([768, 22])\n",
      "torch.Size([22, 22])\n",
      "torch.Size([22, 22])\n",
      "y= torch.Size([22, 768])\n",
      "torch.Size([1, 22])\n",
      "bank ['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n",
      "tensor([[ 32.7842,  61.4429,  97.6800, 151.8367,  92.5404, 119.3528, 242.7067,\n",
      "         154.8098,  33.1573, 104.3848, 230.2765, 143.0902,  85.3533,  68.7504,\n",
      "          62.0727,  58.7767,  97.2471, 109.6828, 118.1705, 139.8130,  32.8859,\n",
      "          96.1952]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sen1 = encoded_layers[11][-1,:,:]\n",
    "print(sen1.shape)\n",
    "sen2 = sen1.transpose(0,1)\n",
    "print(sen2.shape)\n",
    "rw = torch.mm(sen1,sen2)  #torch.bmm(sen1,sen2) for 3 dimensional\n",
    "print(rw.shape)\n",
    "weight = F.softmax(rw,dim=1)\n",
    "print(weight.shape)\n",
    "\n",
    "y = torch.mm(weight, sen1)\n",
    "print('y=',y.shape)\n",
    " \n",
    "i = 6\n",
    "a1 =torch.mm(sen1[i].view(1,-1),y.transpose(0,1))\n",
    "print(a1.shape)\n",
    "print( tokenized_text[i],tokenized_text)\n",
    "print(a1)\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.scatter(tokenized_text,a1[0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here after model described by \n",
    "#http://www.peterbloem.nl/blog/transformers\n",
    "#and code from github \n",
    "#https://github.com/pbloem/former\n",
    "\n",
    "import util\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random, math\n",
    "\n",
    "class SelfAttentionWide(nn.Module):\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "       :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
    "\n",
    "        keys    = self.tokeys(x)   .view(b, t, h, e) \n",
    "        queries = self.toqueries(x).view(b, t, h, e)  \n",
    "        values  = self.tovalues(x) .view(b, t, h, e)  \n",
    "\n",
    "        # compute scaled dot-product self-attention\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "\n",
    "        queries = queries / (e ** (1/4))\n",
    "        keys    = keys / (e ** (1/4))\n",
    "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
    "        #   This should be more memory efficient\n",
    "\n",
    "        # - get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        assert dot.size() == (b*h, t, t)\n",
    "\n",
    "        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n",
    "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
    "\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        # - dot now has row-wise self-attention probabilities\n",
    "\n",
    "        # apply the self attention to the values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, e)\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, h * e)\n",
    "\n",
    "        return self.unifyheads(out)\n",
    "    \n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0, wide=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttentionWide(emb, heads=heads, mask=mask) if wide \\\n",
    "                    else SelfAttentionNarrow(emb, heads=heads, mask=mask)\n",
    "        self.mask = mask\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb)\n",
    "        self.norm2 = nn.LayerNorm(emb)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb, ff_hidden_mult * emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_mult * emb, emb)\n",
    "        )\n",
    "\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attended = self.attention(x)\n",
    "\n",
    "        x = self.norm1(attended + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        fedforward = self.ff(x)\n",
    "\n",
    "        x = self.norm2(fedforward + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for generating text (character by character).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb, heads, depth, seq_length, num_tokens, wide=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=num_tokens)\n",
    "        self.pos_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=seq_length)\n",
    "\n",
    "        tblocks = []\n",
    "        for i in range(depth):\n",
    "            tblocks.append(\n",
    "                TransformerBlock(emb=emb, heads=heads, seq_length=seq_length, mask=True, wide=wide))\n",
    "\n",
    "        self.tblocks = nn.Sequential(*tblocks)\n",
    "\n",
    "        self.toprobs = nn.Linear(emb, num_tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: A (batch, sequence length) integer tensor of token indices.\n",
    "        :return: predicted log-probability vectors for each token based on the preceding tokens.\n",
    "        \"\"\"\n",
    "        tokens = x.cuda()  #self.token_embedding(x)  #hhu\n",
    "        b, t, e = tokens.size()\n",
    "\n",
    "#        positions = self.pos_embedding(torch.arange(t, device='d()'))[None, :, :].expand(b, t, e)\n",
    "        positions = self.pos_embedding(torch.arange(t,device='cuda'))[None, :, :].expand(b, t, e)\n",
    "        x = tokens + positions\n",
    "\n",
    "        x = self.tblocks(x)\n",
    "\n",
    "        x = self.toprobs(x.view(b*t, e)).view(b, t, self.num_tokens)\n",
    "\n",
    "        return F.log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22, 768])\n",
      "torch.Size([22, 768]) torch.Size([22, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 768\n",
    "emb = embedding_size\n",
    "num_heads = 8\n",
    "depth = 1\n",
    "seq_length = 22\n",
    "num_tokens = embedding_size\n",
    "wide = True\n",
    "\n",
    "model = GTransformer(emb=embedding_size, heads=num_heads, depth=depth, seq_length=seq_length, \\\n",
    "                     num_tokens=num_tokens, wide=wide)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "sen2 = sen1.view(1,sen1.size()[0], sen1.size()[1])\n",
    "print(sen2.shape)\n",
    "\n",
    "yy = model(sen2)  # model\n",
    "yy = yy[-1,:,:]\n",
    "print(yy.shape,sen1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22])\n",
      "river ['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb88892c590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 18\n",
    "sen1 = sen1.to('cuda')\n",
    "a1 = torch.mm(sen1[i].view(1,-1),yy.transpose(0,1))\n",
    "print(a1.shape)\n",
    "print( tokenized_text[i],tokenized_text)\n",
    "\n",
    "a1 = a1.cpu() #Move tensor from cuda to cpu\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.scatter(tokenized_text,a1[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
